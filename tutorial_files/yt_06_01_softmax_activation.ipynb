{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why use softmax activation? We want to know how \"wrong\" the output is. Consider the following...\n",
    "```python\n",
    "output1 = [4.8, 1.21, 2.385]\n",
    "output2 = [4.8, 4.79, 4.25]\n",
    "```\n",
    "How do we decide which on is more accurate? Technically they are both the same largest value, but relative to each other they are very different. \n",
    "\n",
    "Could do some kind of probability function / distribution and use the rectified linear function. But negative values won't work and will cause issues later. Clipping values means the model can't learn from that. \n",
    "\n",
    "Basically - we want to make the output something that we can use to teach the model and that make sense.\n",
    "\n",
    "Solution - we use exponentiation to make the values all positive without causing isses that just squareing it would create. We do this with `y=e^x` where `e` is euler's number 2.718281828459045"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "layer_outputs = [[4.8, 1.21, 2.385],\n",
    "                 [8.9, -1.81, 0.2],\n",
    "                 [1.41, 1.051, 0.026]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_values = np.exp(layer_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.21510418e+02, 3.35348465e+00, 1.08590627e+01],\n",
       "       [7.33197354e+03, 1.63654137e-01, 1.22140276e+00],\n",
       "       [4.09595540e+00, 2.86051020e+00, 1.02634095e+00]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_values = exp_values / np.sum(exp_values, axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.95282664e-01 2.47083068e-02 8.00090293e-02]\n",
      " [9.99811129e-01 2.23163963e-05 1.66554348e-04]\n",
      " [5.13097164e-01 3.58333899e-01 1.28568936e-01]]\n",
      "[2.40819096 0.38306452 0.20874452]\n"
     ]
    }
   ],
   "source": [
    "print(norm_values)\n",
    "print(sum(norm_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to subtract the largest output value from the initial values to avoid an overflow error if the \n",
    "output values are very large. The end result is the same, but we prevent a potential overflow condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
